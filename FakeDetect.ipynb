{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeDetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNq/tTe7JHcTae1DxsB/13p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ME0ny/FakeNewsDetection/blob/master/FakeDetect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzWsre9h8ZBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OYOZKnK9GxX",
        "colab_type": "code",
        "outputId": "8fae7ae4-4862-4ff0-dc92-a5f65f24b7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "pip install pytorch-transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.2)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.38.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.12.39)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.15.39)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.39->boto3->pytorch-transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=bcc9cb67fe76ba21acbf698c965412c8362529214e691d42af08b2e2c3cca10b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.41 sentencepiece-0.1.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnpP2QaK9D94",
        "colab_type": "code",
        "outputId": "99488958-bb12-4c7e-ba04-bc498f7f3370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device == torch.device('cpu'):\n",
        "    print('Using cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Tesla P100-PCIE-16GB GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJb-AoL79PVY",
        "colab_type": "code",
        "outputId": "3e8cbbde-53f6-40f7-ef11-dce1c27565c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pos_texts = pd.read_csv('True.csv')\n",
        "neg_texts = pd.read_csv('Fake.csv')\n",
        "pos_texts.sample(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>U.S. small business lobby throws support behin...</td>\n",
              "      <td>WASHINGTON (Reuters) - The National Federation...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>November 9, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21053</th>\n",
              "      <td>Kenya to hold new presidential vote on Oct. 17...</td>\n",
              "      <td>NAIROBI (Reuters) - Kenya will hold a new pres...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>September 4, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16737</th>\n",
              "      <td>Slovakia a pro-European island in its region, ...</td>\n",
              "      <td>BRATISLAVA (Reuters) - Slovakia s prime minist...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>October 23, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2037</th>\n",
              "      <td>Fellow Republicans rebuke Trump over governmen...</td>\n",
              "      <td>WASHINGTON/NEW YORK (Reuters) - President Dona...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>August 23, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15290</th>\n",
              "      <td>SpaceX to launch Turkish satellites, minister ...</td>\n",
              "      <td>ISTANBUL (Reuters) - Turkey s Turksat 5A and 5...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>November 9, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ...                date\n",
              "710    U.S. small business lobby throws support behin...  ...   November 9, 2017 \n",
              "21053  Kenya to hold new presidential vote on Oct. 17...  ...  September 4, 2017 \n",
              "16737  Slovakia a pro-European island in its region, ...  ...   October 23, 2017 \n",
              "2037   Fellow Republicans rebuke Trump over governmen...  ...    August 23, 2017 \n",
              "15290  SpaceX to launch Turkish satellites, minister ...  ...   November 9, 2017 \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcRYC0ZJ_IM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.concatenate([pos_texts['text'].values, neg_texts['text'].values])\n",
        "\n",
        "sentences = [\"[CLS] \" + sentence[:509] + \" [SEP]\" for sentence in sentences]\n",
        "labels = [[0] for _ in range(pos_texts.shape[0])] + [[1] for _ in range(neg_texts.shape[0])]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeg6TlA_S8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACyvtOYb_x2F",
        "colab_type": "code",
        "outputId": "70f0b13d-348f-48fb-9e90-d912cb799f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2576675.29B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'london', '(', 'reuters', ')', '-', 'u', '.', 's', '.', 'secretary', 'of', 'state', 'john', 'kerry', 'said', 'on', 'monday', 'it', 'was', '“', 'inappropriate', '”', 'for', 'donald', 'trump', 'to', 'brand', 'german', 'chancellor', 'angela', 'mer', '##kel', '’', 's', 'refugee', 'policy', '“', 'a', 'catastrophic', 'mistake', '”', '.', '“', 'i', 'thought', 'frankly', 'it', 'was', 'inappropriate', 'for', 'a', 'president', '-', 'elect', 'of', 'the', 'united', 'states', 'to', 'be', 'stepping', 'into', 'the', 'politics', 'of', 'other', 'countries', 'in', 'a', 'quite', 'direct', 'manner', ',', '”', 'kerry', 'told', 'cnn', '’', 's', 'christian', '##e', 'ama', '##np', '##our', 'during', 'a', 'one', '-', 'day', 'visit', 'to', 'london', 'in', 'the', 'last', 'week', 'of', 'the', 'obama', 'administration', '.', '“', 'he', 'will', 'have', 'to', 'speak', 'to', 'that', '.', 'as', 'of', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1_SPH1-_0jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4AnRzOAvYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_gt, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dTKboRQEoFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvFX1N9oErCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfsPUiPHEuna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b3bc7912-01a8-489c-8eae-5de1493829a1"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [0],\n",
              "        ...,\n",
              "        [0],\n",
              "        [1],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuNq0cRFEwRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d198ddb0-444f-4a0f-e477-b621a97ed0fb"
      },
      "source": [
        "print(validation_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [0],\n",
            "        [0],\n",
            "        ...,\n",
            "        [0],\n",
            "        [0],\n",
            "        [0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYw2WTqOEzkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c5851173-56a1-4ff7-bdc2-8909e6d09406"
      },
      "source": [
        "validation_masks"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIuYJSahE2Tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9383964c-9c75-4b3e-f3c5-542eb6e87dc5"
      },
      "source": [
        "validation_inputs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2044,  3666,  ...,     0,     0,     0],\n",
              "        [  101, 10204,  1006,  ...,  1997,  2028,  2007],\n",
              "        [  101,  2414,  1006,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  9925,  1010,  ...,  1010,  1524,  2002],\n",
              "        [  101, 21675,  1006,  ...,  1010,  2040,  3685],\n",
              "        [  101,  3994,  1006,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmQfGaJKE5pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHlsj6mRE7xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g_onBUYE-B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYPtRs2EFBd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIVynmDTFAb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be3ff394-746f-48e4-8e9a-712fe6344d55"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 361/361 [00:00<00:00, 101010.26B/s]\n",
            "100%|██████████| 440473133/440473133 [00:05<00:00, 75090875.20B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsNJCHVnFED8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsOxLmN5FK6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "fd92f9b1-09fe-4ea7-edb3-cb18f547fa4b"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Backward pass\n",
        "    loss[0].backward()\n",
        "    \n",
        "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss[0].item()\n",
        "    \n",
        "    # Рисуем график\n",
        "    clear_output(True)\n",
        "    plt.plot(train_loss_set)\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n",
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)\n",
        "\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss на обучающей выборке: 0.01805\n",
            "Процент правильных предсказаний на валидационной выборке: 99.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17T6tnF0FNOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be92a05f-09b8-4c56-df2e-4583ca842112"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    f1_score(valid_labels, valid_preds) * 100\n",
        "))\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 99.82%\n",
            "Процент правильных предсказаний на валидационной выборке: 99.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXYa5YwqKBcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqzmQ9cEKIfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndzPCfrSKOYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkpgXwsbKRxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ed86cb16-8e76-41c6-8ded-0a2b74b4916e"
      },
      "source": [
        "f1_score_v = f1_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    f1_score_v*100\n",
        "))\n",
        "c = 0\n",
        "for i in range(len(test_labels)):\n",
        "  if(test_labels[i]!=test_preds[i]):\n",
        "    c+=1\n",
        "print('Неправильных предсказаний: {0}/{1}'.format(\n",
        "    c,\n",
        "    len(test_labels)\n",
        "))\n",
        "print(c/len(test_labels))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Процент правильных предсказаний на отложенной выборке составил: 99.92%\n",
            "Неправильных предсказаний: 12/13470\n",
            "0.0008908685968819599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdmVG8cVKfJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "146fb02c-024b-4d24-c16d-015107dac0c0"
      },
      "source": [
        "test_preds[0]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKniLOozLgNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "936e5431-a07a-4fef-d75a-da8bcff74246"
      },
      "source": [
        "sum(test_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v09DOxx7Lijy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_pretrained('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FopAOtubTQxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0aa07fd-2c34-4035-b329-0204049af700"
      },
      "source": [
        "tokenizer.save_pretrained('./') "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./vocab.txt', './special_tokens_map.json', './added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39ucn_aETV2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "192e9a5e-9722-4ddf-90df-9ac780d96201"
      },
      "source": [
        "logits"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.8086627,  4.5313616],\n",
              "       [-3.5258   ,  4.2054653],\n",
              "       [-3.561069 ,  4.317655 ],\n",
              "       [-3.563194 ,  4.325587 ],\n",
              "       [-3.7064922,  4.495109 ],\n",
              "       [ 4.179145 , -4.714635 ],\n",
              "       [ 4.2905445, -5.038616 ],\n",
              "       [-3.7685366,  4.5364256],\n",
              "       [-3.4967387,  4.1189966],\n",
              "       [-3.6522775,  4.4362946],\n",
              "       [-3.7513068,  4.500571 ],\n",
              "       [ 4.338764 , -4.9653034],\n",
              "       [-3.8130512,  4.455117 ],\n",
              "       [ 4.251712 , -4.9945564],\n",
              "       [ 4.3035636, -5.003175 ],\n",
              "       [ 4.1718693, -4.7062683],\n",
              "       [-3.559449 ,  4.2992945],\n",
              "       [ 4.2797284, -4.972843 ],\n",
              "       [-3.6949234,  4.3988414],\n",
              "       [ 4.3325033, -5.0219936],\n",
              "       [-3.8433743,  4.53025  ],\n",
              "       [ 4.3159213, -5.010886 ],\n",
              "       [ 4.237635 , -4.965848 ],\n",
              "       [-2.7167652,  3.2438474],\n",
              "       [ 4.306404 , -5.008828 ],\n",
              "       [-3.7168272,  4.462761 ],\n",
              "       [ 4.3273296, -5.072914 ],\n",
              "       [-3.4867496,  4.2326417],\n",
              "       [ 4.3097215, -4.933014 ],\n",
              "       [-3.6409166,  4.3694515]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRP2tpddbPPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "752dda80-4fde-4f86-ed64-5f806e0ea94c"
      },
      "source": [
        "test_preds[0:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PatLkiEbcoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f7d71d61-d218-47a0-f06e-2b10f435f389"
      },
      "source": [
        "logits[0:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.8086627,  4.5313616],\n",
              "       [-3.5258   ,  4.2054653],\n",
              "       [-3.561069 ,  4.317655 ],\n",
              "       [-3.563194 ,  4.325587 ],\n",
              "       [-3.7064922,  4.495109 ],\n",
              "       [ 4.179145 , -4.714635 ],\n",
              "       [ 4.2905445, -5.038616 ],\n",
              "       [-3.7685366,  4.5364256],\n",
              "       [-3.4967387,  4.1189966],\n",
              "       [-3.6522775,  4.4362946]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU_1hz1dbpHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d77fbd82-c03d-49ad-f198-363cbd501a0d"
      },
      "source": [
        "def main(text):\n",
        "  texts = []\n",
        "  preds = []\n",
        "  texts.append(\"[CLS] \" + text[:509] + \" [SEP]\")\n",
        "  print(texts)\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in texts]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "  )\n",
        "  attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "  prediction_inputs = torch.tensor(input_ids)\n",
        "  prediction_masks = torch.tensor(attention_masks)\n",
        "  \n",
        "  prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks\n",
        "  )\n",
        "\n",
        "  prediction_dataloader = DataLoader(\n",
        "      prediction_data, \n",
        "      sampler=SequentialSampler(prediction_data),\n",
        "      batch_size=1\n",
        "  )\n",
        "  model.eval()\n",
        "  preds = []\n",
        "\n",
        "  for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1) \n",
        "    preds.extend(batch_preds)\n",
        "  return preds\n",
        "print(main('Why He Is Recognizing Jerusalem Today,\"President Donald Trump announced yesterday that he plans to formally recognize Jerusalem as the capital of Israel. While this is left most pundits perplexed, the reasoning is clear. Trump wants to divert attention from Robert Mueller s investigation. It is no coincidence that the day after the news broke that Deutsche Bank has received subpoenas for information on the Trump family s assets, that this Jerusalem decision was announced. What could be a bigger news story than getting this information? A blow up in the Middle East.Look at the reaction world leaders have had to this announcement. American allies throughout the Middle East and Europe have asked Trump not to do this and have stressed how dangerous a statement this is. US News and World Report put this out today: The mere consideration of Trump changing the status quo sparked a renewed U.S. security warning on Tuesday. America s consulate in Jerusalem ordered U.S. personnel and their families to avoid visiting Jerusalem s Old City or the West Bank, and urged American citizens in general to avoid places with increased police or military presence. It is worth noting that while Trump will formally announce that the U.S. will recognize Jerusalem as Israel s capital, there is no movement underway to relocate the embassy from Tel Aviv. In fact, he has signed an order to delay that decision for another six months. This move is necessary due to the 1995 Jerusalem Embassy Act, which mandated the embassy be moved. It also allowed the president to delay that by six months and every president since that act became law has done so this way.The Atlantic has even compared this decision to Trump  wagging the dog,  a reference to a movie where a U.S. president goes to war with Albania to take the public s attention away from his own scandals involving a mistress. The film was viewed as a parody of President Bill Clinton s military actions in Afghanistan and Sudan after he acknowledged an affair with Monica Lewinsky.While whether or not Clinton attacked other countries to distract the nation from his actions with Lewinsky may be a point that is up for debate, it is clear that Trump likes to do things to distract the public s attention. Catherine Rampell wrote about this tactic late last year in the Washington Post. She wrote: Welcome to 2017, the ouroboros of distractions, where every terrible thing is a head-fake for a ruse for a diversion for a misdirection from something else much, much worse. Trump makes announcements, sends tweets and says things without any thought to the real world consequences that follow. Experts in the Middle East fear that the Jerusalem announcement will lead to real deaths. Many people worry  that his thoughtless and impetuous tweets will lead to a nuclear war. His thoughtless comments confuse and enrage many.By making such a move, for such purely personal reasons, Trump is proving, once again, that he is not fit to be president of a condo association, much less of the United States.Featured image by Andrew Burton/Getty Images'))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS] Why He Is Recognizing Jerusalem Today,\"President Donald Trump announced yesterday that he plans to formally recognize Jerusalem as the capital of Israel. While this is left most pundits perplexed, the reasoning is clear. Trump wants to divert attention from Robert Mueller s investigation. It is no coincidence that the day after the news broke that Deutsche Bank has received subpoenas for information on the Trump family s assets, that this Jerusalem decision was announced. What could be a bigger news stor [SEP]']\n",
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ozpK0gdeVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}